{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XAnpr6vR0_D"
      },
      "source": [
        "### Suggestions:\n",
        "##### 1) Reduced training set for faster training\n",
        "##### 2) Low image quality (grey-scale)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jc-BhdKnJRsJ"
      },
      "source": [
        "####  **Importing Required Libraries**\n",
        "\n",
        "**Objective**  \n",
        "This section introduces the libraries and modules required for this lab. These libraries enable efficient data handling, preprocessing, and model building for TinyML applications.\n",
        "\n",
        "**Key Components**  \n",
        "- **TensorFlow**: A powerful framework for building and deploying machine learning models, especially suited for deep learning tasks.  \n",
        "- **TensorFlow Datasets (TFDS)**: A module to download and preprocess datasets like PlantVillage efficiently.  \n",
        "- **Keras Applications**: Provides pre-trained models such as MobileNet, optimized for resource-constrained environments like TinyML.  \n",
        "- **Keras Layers and Models**: Used to customize the architecture for our binary classification task.  \n",
        "- **Adam Optimizer**: A widely-used optimization algorithm for training neural networks efficiently.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vy0nmn4s9oK0",
        "outputId": "44053a76-88a1-42f0-c5f4-7d336e3ecc61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_Iicar-k-vjv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "save_dir = '/content/drive/My Drive/TinyPlants'\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dSr3GAUbEXaD"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.applications import MobileNet\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2XYx35lJatR"
      },
      "source": [
        "#### **Preparing the PlantVillage Dataset**\n",
        "\n",
        "**Objective**  \n",
        "This section focuses on loading, preprocessing, and splitting the PlantVillage dataset into training, validation, and test sets while converting it into a binary classification dataset.\n",
        "\n",
        "**Steps**  \n",
        "1. **Load the Dataset**: Utilize TensorFlow Datasets (TFDS) to download and load the PlantVillage dataset.  \n",
        "2. **Define Healthy Classes**: Specify the \"healthy\" classes from the dataset's class list. All other classes are automatically labeled as \"unhealthy.\"  \n",
        "3. **Relabel the Dataset**: Implement a mapping function to convert multi-class labels into binary labels (`0` for healthy, `1` for unhealthy).  \n",
        "4. **Split the Dataset**: Divide the dataset into training (40,000 samples), validation (7,000 samples), and test sets.  \n",
        "5. **Preprocess Images**: Resize images to the input size expected by MobileNet and normalize pixel values to the range [0, 1].\n",
        "\n",
        "**Outcome**  \n",
        "This step produces preprocessed datasets ready for training, validation, and evaluation, tailored for binary classification tasks.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the PlantVillage dataset\n",
        "dataset, info = tfds.load('plant_village', with_info=True, as_supervised=True)\n",
        "\n",
        "# Define the \"healthy\" classes\n",
        "healthy_classes = [\n",
        "    'Apple___healthy', 'Blueberry___healthy', 'Cherry___healthy',\n",
        "    'Corn___healthy', 'Grape___healthy', 'Peach___healthy',\n",
        "    'Pepper,_bell___healthy', 'Potato___healthy', 'Raspberry___healthy',\n",
        "    'Soybean___healthy', 'Strawberry___healthy', 'Tomato___healthy'\n",
        "]\n",
        "\n",
        "# Get class names from the dataset info\n",
        "class_names = info.features['label'].names\n",
        "\n",
        "# Function to map original labels to binary labels\n",
        "def map_to_binary_label(image, label):\n",
        "    class_name = class_names[label]\n",
        "    if class_name in healthy_classes:\n",
        "        new_label = 0  # Healthy\n",
        "    else:\n",
        "        new_label = 1  # Unhealthy\n",
        "    return image, new_label\n",
        "\n",
        "# Corrected function to map original labels to binary labels\n",
        "def map_to_binary_label(image, label):\n",
        "    class_name = tf.gather(class_names, tf.cast(label, tf.int32))  # Convert label to int and get class name\n",
        "    new_label = tf.cond(\n",
        "        tf.reduce_any(tf.equal(class_name, healthy_classes)),\n",
        "        lambda: tf.constant(0),  # Healthy\n",
        "        lambda: tf.constant(1)   # Unhealthy\n",
        "    )\n",
        "    return image, new_label\n",
        "\n",
        "# Apply the corrected mapping function\n",
        "binary_train_dataset = dataset['train'].map(map_to_binary_label)\n",
        "\n",
        "\n",
        "# Split into training, validation, and test sets\n",
        "train_dataset = binary_train_dataset.take(40000)\n",
        "val_dataset = binary_train_dataset.skip(40000).take(7000)\n",
        "test_dataset = binary_train_dataset.skip(47000)\n",
        "\n",
        "# Image preprocessing\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "def preprocess_image(image, label):\n",
        "    image = tf.image.resize(image, IMG_SIZE)\n",
        "    image = image / 255.0  # Normalize to [0,1] range\n",
        "    return image, label\n",
        "\n",
        "# Preprocess the datasets\n",
        "train_dataset = train_dataset.map(preprocess_image).shuffle(1000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "val_dataset = val_dataset.map(preprocess_image).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.map(preprocess_image).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150,
          "referenced_widgets": [
            "d89cf9958a63416b8822b1b7a9fbd48b",
            "c31bab3df42046c38e2d0ebe803e5035",
            "e394e6590b68472bb2770a67b013035b",
            "223f00f3383a4281bdc79d0e3a994c22",
            "1cc63dcba73845a9a3dd329364f532b6",
            "2a44a75752904fd0adea22e6bd42633f",
            "73914941da9b4d438861f73b4cc51f88",
            "8c1dc8b1de6a4dc284922ae0282e05e9",
            "2f134eaec1f84a049ab659bb356b423f",
            "c8646e704b18460abbf1ace2ba16f77e",
            "d9775e08b38d4661a729210579f0532d",
            "d976dbffe1b04dada746cad34f4ea84a",
            "815c3685216d490ba86210681749163c",
            "a46b3fbc65694a1eb1556ef59479b3be",
            "958a59c204a54cbe92d33ae1e2af3a62",
            "82fc0044b9bc4f9abfcae00481eb5caa",
            "61844a5ee65244669c2d1a60bb4f8525",
            "c593e172aea1481ca3be8c0f0e4ff8a8",
            "7541b3cd8e484359a58b7b9fdb8996d6",
            "4b63265d52284994baf5c222112138f1",
            "afdc77d1164a458780ed35321f12fce5",
            "33d6d6f774284347b6be75f31dc5645f",
            "25d54638d81a4db4860747ac9bb2d57b",
            "dab30bb4d9874728a843e2a070032686",
            "87c045c64d954b729667c462627fda24",
            "d97dd59afa184cfc88253ac09aa91d6e",
            "97815522a14f42a593c9c9e5cbc3f267",
            "3dce107f39db4529b141cde8f873858d",
            "5a6e44223043495599b3b66af106212c",
            "09e557922de2487697b92b8829343a72",
            "f6d85f5ab9fa46a39d46383325063e04",
            "2f59423cbf164f66b204ee49f1739040",
            "b23856bfc734495b976eff1356432c6a"
          ]
        },
        "id": "sYQ1qR7ROhCz",
        "outputId": "caa4c704-8052-4b70-e628-b0343e156387"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset 827.82 MiB (download: 827.82 MiB, generated: 815.37 MiB, total: 1.60 GiB) to /root/tensorflow_datasets/plant_village/1.0.2...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dl Completed...: 0 url [00:00, ? url/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d89cf9958a63416b8822b1b7a9fbd48b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dl Size...: 0 MiB [00:00, ? MiB/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d976dbffe1b04dada746cad34f4ea84a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Extraction completed...: 0 file [00:00, ? file/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "25d54638d81a4db4860747ac9bb2d57b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names"
      ],
      "metadata": {
        "id": "PMhx6FWSP5fz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, j in dataset['train']:\n",
        "  print(i.shape,j)\n",
        "  break"
      ],
      "metadata": {
        "id": "XQq8O4OKSmgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Corrected function to map original labels to binary labels\n",
        "def map_to_binary_label(image, label):\n",
        "    class_name = tf.gather(class_names, tf.cast(label, tf.int32))  # Convert label to int and get class name\n",
        "    new_label = tf.cond(\n",
        "        tf.reduce_any(tf.equal(class_name, healthy_classes)),\n",
        "        lambda: tf.constant(0),  # Healthy\n",
        "        lambda: tf.constant(1)   # Unhealthy\n",
        "    )\n",
        "    return image, new_label\n",
        "\n",
        "binary_train_dataset = dataset['train'].map(map_to_binary_label)"
      ],
      "metadata": {
        "id": "ux9KhG6GQBI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, j in binary_train_dataset:\n",
        "  print(i.shape , j)\n",
        "  break"
      ],
      "metadata": {
        "id": "7LWec5HRS-kC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in train_dataset:\n",
        "  print(i[0].shape)\n",
        "  break"
      ],
      "metadata": {
        "id": "Fp5vfKrmTVbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-Y4G7S0EwWl"
      },
      "outputs": [],
      "source": [
        "# Load the PlantVillage dataset\n",
        "dataset, info = tfds.load('plant_village', with_info=True, as_supervised=True)\n",
        "\n",
        "# Define the \"healthy\" classes\n",
        "healthy_classes = [\n",
        "    'Apple___healthy', 'Blueberry___healthy', 'Cherry___healthy',\n",
        "    'Corn___healthy', 'Grape___healthy', 'Peach___healthy',\n",
        "    'Pepper,_bell___healthy', 'Potato___healthy', 'Raspberry___healthy',\n",
        "    'Soybean___healthy', 'Strawberry___healthy', 'Tomato___healthy'\n",
        "]\n",
        "\n",
        "# Get class names from the dataset info\n",
        "class_names = info.features['label'].names\n",
        "\n",
        "# Function to map original labels to binary labels\n",
        "def map_to_binary_label(image, label):\n",
        "    class_name = class_names[label]\n",
        "    if class_name in healthy_classes:\n",
        "        new_label = 0  # Healthy\n",
        "    else:\n",
        "        new_label = 1  # Unhealthy\n",
        "    return image, new_label\n",
        "\n",
        "# Corrected function to map original labels to binary labels\n",
        "def map_to_binary_label(image, label):\n",
        "    class_name = tf.gather(class_names, tf.cast(label, tf.int32))  # Convert label to int and get class name\n",
        "    new_label = tf.cond(\n",
        "        tf.reduce_any(tf.equal(class_name, healthy_classes)),\n",
        "        lambda: tf.constant(0),  # Healthy\n",
        "        lambda: tf.constant(1)   # Unhealthy\n",
        "    )\n",
        "    return image, new_label\n",
        "\n",
        "# Apply the corrected mapping function\n",
        "binary_train_dataset = dataset['train'].map(map_to_binary_label)\n",
        "\n",
        "\n",
        "# Split into training, validation, and test sets\n",
        "train_dataset = binary_train_dataset.take(40000)\n",
        "val_dataset = binary_train_dataset.skip(40000).take(7000)\n",
        "test_dataset = binary_train_dataset.skip(47000)\n",
        "\n",
        "# Image preprocessing\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "def preprocess_image(image, label):\n",
        "    image = tf.image.resize(image, IMG_SIZE)\n",
        "    image = image / 255.0  # Normalize to [0,1] range\n",
        "    return image, label\n",
        "\n",
        "# Preprocess the datasets\n",
        "train_dataset = train_dataset.map(preprocess_image).shuffle(1000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "val_dataset = val_dataset.map(preprocess_image).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.map(preprocess_image).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TW9iZxvJJhf2"
      },
      "source": [
        "#### **Visualizing Healthy and Unhealthy Leaves**\n",
        "\n",
        "**Objective**  \n",
        "This section introduces a visualization step to better understand the dataset. It plots examples of healthy and unhealthy plant leaves from the training dataset.\n",
        "\n",
        "**Steps**  \n",
        "1. **Helper Functions**:  \n",
        "   - `plot_images`: Displays a grid of images with labels.  \n",
        "   - `collect_examples`: Extracts a specified number of healthy and unhealthy images for visualization.  \n",
        "2. **Visualization**: Visualize 5 healthy and 5 unhealthy plant leaves from the training dataset.  \n",
        "   - Healthy leaves are labeled as `Healthy`.  \n",
        "   - Unhealthy leaves are labeled as `Unhealthy`.\n",
        "\n",
        "**Outcome**  \n",
        "This step helps participants familiarize themselves with the dataset and ensures the binary labeling was applied correctly. It also emphasizes the importance of understanding the dataset before training a model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XMYuSJFoGSwm"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Helper function to display images with labels\n",
        "def plot_images(images, labels, title):\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    for i in range(len(images)):\n",
        "        plt.subplot(2, 5, i + 1)\n",
        "        plt.imshow(images[i])\n",
        "        plt.title('Healthy' if labels[i] == 0 else 'Unhealthy')\n",
        "        plt.axis('off')\n",
        "    plt.suptitle(title)\n",
        "    plt.show()\n",
        "\n",
        "# Function to collect 5 healthy and 5 unhealthy examples\n",
        "def collect_examples(dataset, num_per_class=5):\n",
        "    healthy_images = []\n",
        "    unhealthy_images = []\n",
        "    for image, label in dataset.unbatch():  # Unbatch to iterate over individual samples\n",
        "        if len(healthy_images) < num_per_class and label.numpy() == 0:\n",
        "            healthy_images.append(image.numpy())\n",
        "        elif len(unhealthy_images) < num_per_class and label.numpy() == 1:\n",
        "            unhealthy_images.append(image.numpy())\n",
        "        # Stop once we have enough examples\n",
        "        if len(healthy_images) == num_per_class and len(unhealthy_images) == num_per_class:\n",
        "            break\n",
        "    return healthy_images, unhealthy_images\n",
        "\n",
        "# Collect examples from the training dataset\n",
        "healthy_images, unhealthy_images = collect_examples(train_dataset)\n",
        "\n",
        "# Plot healthy and unhealthy images\n",
        "plot_images(healthy_images, [0] * len(healthy_images), title=\"Healthy Plant Leaves\")\n",
        "plot_images(unhealthy_images, [1] * len(unhealthy_images), title=\"Unhealthy Plant Leaves\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kfk3l2RKd5u"
      },
      "source": [
        "# Fine-Tuning MobileNetV2 with Mixed Precision for Binary Classification\n",
        "\n",
        "## Objective\n",
        "This section focuses on building and fine-tuning a pre-trained MobileNetV2 model with mixed precision to classify plant leaves as healthy or unhealthy. Mixed precision allows faster computation and reduced memory usage by leveraging the efficiency of lower-precision arithmetic.\n",
        "\n",
        "\n",
        "\n",
        "## Steps\n",
        "\n",
        "1. **Load MobileNetV2**: Use a pre-trained MobileNetV2 model with ImageNet weights, excluding the top layers to allow for custom modifications.\n",
        "\n",
        "2. **Enable Mixed Precision**: Configure TensorFlow to use mixed precision by setting the global precision policy to `mixed_float16`. This enables compatible layers and operations to use 16-bit precision automatically while keeping the output layer and loss functions in 32-bit precision for stability.\n",
        "\n",
        "  ### What is Mixed Precision?\n",
        "  **Mixed precision training** uses both 16-bit (half-precision) and 32-bit (single-precision) floating-point data types during model training. In modern deep learning hardware, such as NVIDIA GPUs with Tensor Cores, operations in 16-bit precision are significantly faster than in 32-bit precision. Mixed precision training allows for:\n",
        "  - **Faster computation**: 16-bit operations are optimized on supported hardware.\n",
        "  - **Lower memory usage**: Reduces memory requirements, enabling larger batch sizes or more complex models.\n",
        "  - **Maintained accuracy**: The model retains high numerical precision for critical operations (e.g., loss calculation and gradients) while benefiting from faster 16-bit arithmetic.\n",
        "\n",
        "  ### Advantages of Mixed Precision\n",
        "  - **Speed**: Reduces the time needed for each training step, especially when using GPUs with Tensor Cores.\n",
        "  - **Memory Efficiency**: Enables the use of larger batch sizes or models with more parameters.\n",
        "  - **Scalability**: Suitable for deploying resource-efficient models on edge devices or in production.\n",
        "\n",
        "  With these optimizations, the model is ready for efficient inference tasks and can be deployed in environments with limited computational resources.\n",
        "\n",
        "3. **Freeze Base Layers**: Prevent updates to the pre-trained weights during training to leverage pre-learned features effectively.\n",
        "\n",
        "4. **Add Custom Layers**: Include a global average pooling layer, a dense layer for feature extraction, and an output layer for binary classification (using sigmoid activation). The output layer uses `dtype='float32'` to ensure compatibility with the binary cross-entropy loss.\n",
        "\n",
        "5. **Compile the Model**: Use the Adam optimizer with a learning rate of 0.001, binary cross-entropy loss function, and accuracy as a performance metric.\n",
        "\n",
        "6. **Optimize Dataset Pipeline**: Use TensorFlow's `tf.data` API to prefetch data, ensuring efficient data loading during training and validation.\n",
        "\n",
        "7. **Train the Model**: Train the model using the prepared training and validation datasets for 10 epochs. The mixed precision policy improves training speed on supported hardware.\n",
        "\n",
        "8. **Evaluate the Model**: Test the model on the test dataset to evaluate its performance and display the test accuracy.\n",
        "\n",
        "9. **Save the Model**: Save the fine-tuned MobileNetV2 model in the recommended `.keras` format for future deployment or inference tasks.\n",
        "\n",
        "## Outcome\n",
        "By the end of this section, participants will have:\n",
        "- Trained a compact, efficient model optimized for TinyML applications.\n",
        "- Leveraged mixed precision training for faster computation and reduced memory consumption without compromising model accuracy.\n",
        "- Saved the trained model in a modern format for deployment on resource-constrained devices.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0PPafyH3wPsk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "\n",
        "# Function to collect and save examples as .jpg\n",
        "def collect_and_save_examples(dataset, save_dir, num_per_class=10):\n",
        "    # Create directories for saving images\n",
        "    healthy_dir = os.path.join(save_dir, \"healthy\")\n",
        "    unhealthy_dir = os.path.join(save_dir, \"unhealthy\")\n",
        "    os.makedirs(healthy_dir, exist_ok=True)\n",
        "    os.makedirs(unhealthy_dir, exist_ok=True)\n",
        "\n",
        "    healthy_images_saved = 0\n",
        "    unhealthy_images_saved = 0\n",
        "\n",
        "    for image, label in dataset.unbatch():  # Unbatch to iterate over individual samples\n",
        "        # Resize image to 224x224\n",
        "        image_resized = tf.image.resize(image, (224, 224)).numpy()\n",
        "        image_resized = (image_resized * 255).astype(\"uint8\")  # Convert to 8-bit image\n",
        "\n",
        "        # Determine save path\n",
        "        if healthy_images_saved < num_per_class and label.numpy() == 0:\n",
        "            save_path = os.path.join(healthy_dir, f\"healthy_{healthy_images_saved + 1}.jpg\")\n",
        "            healthy_images_saved += 1\n",
        "        elif unhealthy_images_saved < num_per_class and label.numpy() == 1:\n",
        "            save_path = os.path.join(unhealthy_dir, f\"unhealthy_{unhealthy_images_saved + 1}.jpg\")\n",
        "            unhealthy_images_saved += 1\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "        # Save the image\n",
        "        Image.fromarray(image_resized).save(save_path)\n",
        "\n",
        "        # Stop if we have enough examples\n",
        "        if healthy_images_saved == num_per_class and unhealthy_images_saved == num_per_class:\n",
        "            break\n",
        "\n",
        "    print(f\"Saved {healthy_images_saved} healthy images and {unhealthy_images_saved} unhealthy images.\")\n",
        "\n",
        "# Example usage\n",
        "# Assuming `train_dataset` is your TensorFlow dataset\n",
        "save_directory = save_dir\n",
        "collect_and_save_examples(train_dataset, save_dir=save_directory, num_per_class=10)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iu1LVO1518MK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "num7XcQ7JNdC"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Enable mixed precision for faster training\n",
        "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
        "\n",
        "# Load pre-trained MobileNetV2 model\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the base model layers\n",
        "base_model.trainable = False\n",
        "\n",
        "# Add custom layers for binary classification\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dense(1, activation='sigmoid', dtype='float32')(x)  # Ensure output dtype is float32\n",
        "\n",
        "# Create the full model\n",
        "model = Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Optimize dataset pipeline\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "val_dataset = val_dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHUyWevbczuT"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=1\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(test_dataset)\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "# Save the model in Keras format\n",
        "model.save(os.path.join(save_dir,'mobilenet_finetuned_binary_plant_village.keras'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJ8-IkxVO2EF"
      },
      "source": [
        "## Saving the Model to Google Drive\n",
        "\n",
        "This section demonstrates how to save the fine-tuned MobileNetV2 model to a folder named `TinyPlants` in your Google Drive. By following these steps, you can ensure that the trained model is stored securely and can be accessed later for deployment or further experimentation.\n",
        "\n",
        "### Steps:\n",
        "1. **Mount Google Drive**: Connect your Google Drive to the Colab environment to enable file saving and retrieval.\n",
        "2. **Create Folder**: Check if the `TinyPlants` folder exists in your Google Drive. If not, create it automatically.\n",
        "3. **Save the Model**: Save the fine-tuned model in the `.keras` format to the `TinyPlants` folder for easy organization and access.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xN-lrjeOmwy"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CysjvqzaOnF5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# Save the model in Keras format to the specified directory\n",
        "# Define Google Drive save paths in the TinyPlants folder\n",
        "save_dir = '/content/drive/My Drive/TinyPlants'\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "\n",
        "model_path = os.path.join(save_dir, 'mobilenet_finetuned_binary_plant_village.keras')\n",
        "model.save(model_path)\n",
        "\n",
        "print(f\"Model saved to {model_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJJH8ulnPZjd"
      },
      "source": [
        "## Converting the Model to TensorFlow Lite with Integer Quantization\n",
        "\n",
        "This section demonstrates how to convert the trained Keras model into a TensorFlow Lite model with integer quantization, ensuring that the input tensors have the correct dimensions required for TensorFlow Lite. Integer quantization optimizes the model for deployment on resource-constrained devices, like microcontrollers, while maintaining accuracy.\n",
        "\n",
        "### Key Steps:\n",
        "\n",
        "1. **Representative Dataset**:\n",
        "   - A subset of the training data is used to calibrate the quantization process, ensuring accurate scaling of weights and activations during integer quantization.\n",
        "\n",
        "2. **Correct Input Shape for Representative Dataset**:\n",
        "   - TensorFlow Lite requires inputs to have a batch dimension, making the input shape `[batch_size, height, width, channels]`.\n",
        "   - This issue is addressed by using `tf.expand_dims()` to add a batch dimension to the images in the representative dataset.\n",
        "\n",
        "3. **Conversion Process**:\n",
        "   - The TensorFlow Lite converter is configured to use integer quantization (`TFLITE_BUILTINS_INT8`) and fallback to TensorFlow operations (`SELECT_TF_OPS`) for unsupported layers.\n",
        "\n",
        "4. **Save the Quantized Model**:\n",
        "   - The quantized model is saved as `mobilenet_quantized_binary_plant_village.tflite` for deployment.\n",
        "\n",
        "### Benefits of Integer Quantization:\n",
        "- Reduces model size and memory usage, making it suitable for TinyML applications.\n",
        "- Increases inference speed on devices with hardware acceleration for integer arithmetic.\n",
        "- Maintains high accuracy through proper calibration using the representative dataset.\n",
        "\n",
        "By the end of this section, the fine-tuned MobileNetV2 model is converted into a lightweight, quantized format, ready for deployment on edge devices.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xk-XtEYsOrCX"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "FZV6mRvwOrjb",
        "outputId": "c643ec8a-289c-4bf6-8dae-1a6796526463"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'os' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-11f8b6bb3b08>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load the .keras model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'mobilenet_finetuned_binary_plant_village.keras'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Define the representative dataset for quantization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load the .keras model\n",
        "model = tf.keras.models.load_model(os.path.join(save_dir,'mobilenet_finetuned_binary_plant_village.keras'))\n",
        "\n",
        "# Define the representative dataset for quantization\n",
        "def representative_dataset():\n",
        "    for image, _ in train_dataset.unbatch().take(100):  # Take 100 samples from training data\n",
        "        image = tf.expand_dims(image, axis=0)  # Add a batch dimension\n",
        "        yield [tf.cast(image, tf.float32)]\n",
        "\n",
        "# Convert the loaded Keras model to TensorFlow Lite format with integer quantization\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_dataset\n",
        "\n",
        "# Enable fallback to allow unsupported ops to use float\n",
        "converter.target_spec.supported_ops = [\n",
        "    tf.lite.OpsSet.TFLITE_BUILTINS_INT8,  # Use integer ops when possible\n",
        "    tf.lite.OpsSet.SELECT_TF_OPS          # Fallback to TensorFlow ops if needed\n",
        "]\n",
        "# converter.inference_input_type = tf.int8  # Quantize input to int8\n",
        "# converter.inference_output_type = tf.int8  # Quantize output to int8\n",
        "\n",
        "# Convert the model\n",
        "quantized_model = converter.convert()\n",
        "\n",
        "# Save the quantized model\n",
        "quantized_model_path = os.path.join(save_dir,'mobilenet_quantized_binary_plant_village.tflite')\n",
        "with open(quantized_model_path, 'wb') as f:\n",
        "    f.write(quantized_model)\n",
        "\n",
        "print(f\"Quantized model saved as '{quantized_model_path}'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kG4mxGpQgUfI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Define Google Drive save paths in the TinyPlants folder\n",
        "save_dir = '/content/drive/My Drive/TinyPlants'\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "\n",
        "quantized_model_path = os.path.join(save_dir, 'mobilenet_quantized_binary_plant_village.tflite')\n",
        "with open(quantized_model_path, 'wb') as f:\n",
        "    f.write(quantized_model)\n",
        "\n",
        "print(f\"Quantized model saved to Google Drive at '{quantized_model_path}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dgdCiC9e2B3D"
      },
      "outputs": [],
      "source": [
        "tflite_model_path = (os.path.join(save_dir,'mobilenet_quantized_binary_plant_village.tflite'))\n",
        "with open(tflite_model_path, 'rb') as f:\n",
        "    tflite_model = f.read()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTAnYlASRugY"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NI0UBDkpRu4b"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import time\n",
        "import os\n",
        "\n",
        "\n",
        "# Load the original Keras model\n",
        "original_model = tf.keras.models.load_model(os.path.join(save_dir,'mobilenet_finetuned_binary_plant_village.keras'))\n",
        "\n",
        "# Load the TFLite quantized model\n",
        "tflite_model_path = (os.path.join(save_dir,'mobilenet_quantized_binary_plant_village.tflite'))\n",
        "with open(tflite_model_path, 'rb') as f:\n",
        "    tflite_model = f.read()\n",
        "\n",
        "# Helper function to evaluate the TFLite model\n",
        "def evaluate_tflite_model(tflite_model, test_dataset):\n",
        "    # Initialize the TFLite interpreter\n",
        "    interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "    interpreter.allocate_tensors()\n",
        "\n",
        "    # Get input and output details\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "    for image, label in test_dataset.unbatch():\n",
        "        # Preprocess the image\n",
        "        input_data = tf.cast(image, tf.int8 if input_details[0]['dtype'] == tf.int8 else tf.float32)\n",
        "        input_data = tf.expand_dims(input_data, axis=0)  # Add batch dimension\n",
        "\n",
        "        # Set the input tensor\n",
        "        interpreter.set_tensor(input_details[0]['index'], input_data.numpy())\n",
        "        interpreter.invoke()\n",
        "\n",
        "        # Get the prediction\n",
        "        output = interpreter.get_tensor(output_details[0]['index'])\n",
        "        predicted_label = tf.round(tf.sigmoid(output)).numpy()[0][0]\n",
        "        if predicted_label == label.numpy():\n",
        "            correct_predictions += 1\n",
        "        total_samples += 1\n",
        "\n",
        "    # Calculate accuracy\n",
        "    return correct_predictions / total_samples\n",
        "\n",
        "# Evaluate the original model\n",
        "original_start_time = time.time()\n",
        "original_test_loss, original_test_acc = original_model.evaluate(test_dataset, verbose=0)\n",
        "original_latency = (time.time() - original_start_time) / len(list(test_dataset.unbatch()))\n",
        "original_size = os.path.getsize((os.path.join(save_dir,'mobilenet_finetuned_binary_plant_village.keras'))) / 1024  # in KB\n",
        "\n",
        "# Evaluate the TFLite model\n",
        "tflite_start_time = time.time()\n",
        "tflite_test_acc = evaluate_tflite_model(tflite_model, test_dataset)\n",
        "tflite_latency = (time.time() - tflite_start_time) / len(list(test_dataset.unbatch()))\n",
        "tflite_size = os.path.getsize(tflite_model_path) / 1024  # in KB\n",
        "\n",
        "# Print the comparison results\n",
        "print(f\"Model Comparison:\")\n",
        "print(f\"1. Model Size:\")\n",
        "print(f\"   - Original Model: {original_size:.2f} KB\")\n",
        "print(f\"   - TFLite Model: {tflite_size:.2f} KB\")\n",
        "print(f\"2. Latency (seconds per sample):\")\n",
        "print(f\"   - Original Model: {original_latency:.4f} s/sample\")\n",
        "print(f\"   - TFLite Model: {tflite_latency:.4f} s/sample\")\n",
        "print(f\"3. Accuracy on Test Data:\")\n",
        "print(f\"   - Original Model: {original_test_acc:.4f}\")\n",
        "print(f\"   - TFLite Model: {tflite_test_acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0_93svoS9aU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "osZKiK6OpJV5"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Paths for saved models\n",
        "base_model_path = '/content/drive/My Drive/TinyPlants/mobilenet_finetuned_binary_plant_village.keras'\n",
        "tflite_model_path = '/content/drive/My Drive/TinyPlants/mobilenet_quantized_binary_plant_village.tflite'\n",
        "\n",
        "# Check if files exist\n",
        "assert os.path.exists(base_model_path), \"Base model file not found!\"\n",
        "assert os.path.exists(tflite_model_path), \"TFLite model file not found!\"\n",
        "\n",
        "# Load the original model without the optimizer state\n",
        "original_model = tf.keras.models.load_model(base_model_path, compile=False)\n",
        "\n",
        "# Compile the model\n",
        "original_model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Load the TFLite quantized model content\n",
        "with open(tflite_model_path, 'rb') as f:\n",
        "    tflite_model = f.read()\n",
        "\n",
        "# Helper function to evaluate the TFLite model\n",
        "def evaluate_tflite_model(tflite_model, test_dataset):\n",
        "    interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "    interpreter.allocate_tensors()\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for image, label in test_dataset.take(100):  # Use only 100 samples for evaluation\n",
        "        # Preprocess image\n",
        "        input_data = tf.image.resize(image, (224, 224))  # Resize image\n",
        "        input_data = tf.cast(input_data / 255.0, tf.float32)  # Normalize image\n",
        "        if input_details[0]['dtype'] == tf.int8:\n",
        "            input_data = tf.cast(input_data * 127.0, tf.int8)  # Quantize image\n",
        "        input_data = tf.expand_dims(input_data, axis=0)  # Add batch dimension\n",
        "\n",
        "        # Set input tensor\n",
        "        interpreter.set_tensor(input_details[0]['index'], input_data.numpy())\n",
        "        interpreter.invoke()\n",
        "\n",
        "        # Get prediction\n",
        "        output = interpreter.get_tensor(output_details[0]['index'])\n",
        "        predicted_label = int(tf.round(tf.sigmoid(output)).numpy()[0][0])\n",
        "        if predicted_label == label.numpy():\n",
        "            correct_predictions += 1\n",
        "        total_samples += 1\n",
        "\n",
        "    return correct_predictions / total_samples\n",
        "\n",
        "# Preprocess the test dataset to match model input requirements\n",
        "def preprocess_dataset(image, label):\n",
        "    image = tf.image.resize(image, (224, 224))  # Resize image to (224, 224)\n",
        "    image = tf.cast(image / 255.0, tf.float32)  # Normalize image to [0, 1]\n",
        "    return image, label\n",
        "\n",
        "# Unbatch, preprocess, and batch the test dataset correctly\n",
        "test_dataset_subset = test_dataset.unbatch().map(preprocess_dataset).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Evaluate the original model\n",
        "original_test_loss, original_test_acc = original_model.evaluate(test_dataset_subset, verbose=0)\n",
        "\n",
        "# Free memory after evaluating the original model\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# Evaluate the TFLite model\n",
        "tflite_test_acc = evaluate_tflite_model(tflite_model, test_dataset_subset.unbatch())\n",
        "original_size = os.path.getsize(base_model_path) / 1024  # KB\n",
        "tflite_size = os.path.getsize(tflite_model_path) / 1024  # KB\n",
        "\n",
        "# Print results\n",
        "print(f\"Model Comparison:\")\n",
        "print(f\"1. Model Size:\")\n",
        "print(f\"   - Original Model: {original_size:.2f} KB\")\n",
        "print(f\"   - TFLite Model: {tflite_size:.2f} KB\")\n",
        "print(f\"2. Accuracy on Test Data:\")\n",
        "print(f\"   - Original Model: {original_test_acc:.4f}\")\n",
        "print(f\"   - TFLite Model: {tflite_test_acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7vdrS3fqlz5"
      },
      "outputs": [],
      "source": [
        "assert os.path.exists(tflite_model_path), f\"TFLite model file not found at {tflite_model_path}\"\n",
        "print(f\"TFLite model file exists: {tflite_model_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgNlCz5-qzX9"
      },
      "outputs": [],
      "source": [
        "with open(tflite_model_path, 'rb') as f:\n",
        "    tflite_model = f.read()\n",
        "\n",
        "assert tflite_model, \"Failed to load TFLite model content\"\n",
        "print(f\"TFLite model loaded successfully, size: {len(tflite_model)} bytes\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "924ArlFarq_k"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d89cf9958a63416b8822b1b7a9fbd48b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c31bab3df42046c38e2d0ebe803e5035",
              "IPY_MODEL_e394e6590b68472bb2770a67b013035b",
              "IPY_MODEL_223f00f3383a4281bdc79d0e3a994c22"
            ],
            "layout": "IPY_MODEL_1cc63dcba73845a9a3dd329364f532b6"
          }
        },
        "c31bab3df42046c38e2d0ebe803e5035": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a44a75752904fd0adea22e6bd42633f",
            "placeholder": "​",
            "style": "IPY_MODEL_73914941da9b4d438861f73b4cc51f88",
            "value": "Dl Completed...: 100%"
          }
        },
        "e394e6590b68472bb2770a67b013035b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c1dc8b1de6a4dc284922ae0282e05e9",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2f134eaec1f84a049ab659bb356b423f",
            "value": 1
          }
        },
        "223f00f3383a4281bdc79d0e3a994c22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8646e704b18460abbf1ace2ba16f77e",
            "placeholder": "​",
            "style": "IPY_MODEL_d9775e08b38d4661a729210579f0532d",
            "value": " 1/1 [04:09&lt;00:00, 50.70s/ url]"
          }
        },
        "1cc63dcba73845a9a3dd329364f532b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a44a75752904fd0adea22e6bd42633f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73914941da9b4d438861f73b4cc51f88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c1dc8b1de6a4dc284922ae0282e05e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "2f134eaec1f84a049ab659bb356b423f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c8646e704b18460abbf1ace2ba16f77e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9775e08b38d4661a729210579f0532d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d976dbffe1b04dada746cad34f4ea84a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_815c3685216d490ba86210681749163c",
              "IPY_MODEL_a46b3fbc65694a1eb1556ef59479b3be",
              "IPY_MODEL_958a59c204a54cbe92d33ae1e2af3a62"
            ],
            "layout": "IPY_MODEL_82fc0044b9bc4f9abfcae00481eb5caa"
          }
        },
        "815c3685216d490ba86210681749163c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61844a5ee65244669c2d1a60bb4f8525",
            "placeholder": "​",
            "style": "IPY_MODEL_c593e172aea1481ca3be8c0f0e4ff8a8",
            "value": "Dl Size...: 100%"
          }
        },
        "a46b3fbc65694a1eb1556ef59479b3be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7541b3cd8e484359a58b7b9fdb8996d6",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4b63265d52284994baf5c222112138f1",
            "value": 1
          }
        },
        "958a59c204a54cbe92d33ae1e2af3a62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afdc77d1164a458780ed35321f12fce5",
            "placeholder": "​",
            "style": "IPY_MODEL_33d6d6f774284347b6be75f31dc5645f",
            "value": " 827/827 [04:09&lt;00:00, 15.57 MiB/s]"
          }
        },
        "82fc0044b9bc4f9abfcae00481eb5caa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61844a5ee65244669c2d1a60bb4f8525": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c593e172aea1481ca3be8c0f0e4ff8a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7541b3cd8e484359a58b7b9fdb8996d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "4b63265d52284994baf5c222112138f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "afdc77d1164a458780ed35321f12fce5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33d6d6f774284347b6be75f31dc5645f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25d54638d81a4db4860747ac9bb2d57b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dab30bb4d9874728a843e2a070032686",
              "IPY_MODEL_87c045c64d954b729667c462627fda24",
              "IPY_MODEL_d97dd59afa184cfc88253ac09aa91d6e"
            ],
            "layout": "IPY_MODEL_97815522a14f42a593c9c9e5cbc3f267"
          }
        },
        "dab30bb4d9874728a843e2a070032686": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3dce107f39db4529b141cde8f873858d",
            "placeholder": "​",
            "style": "IPY_MODEL_5a6e44223043495599b3b66af106212c",
            "value": "Extraction completed...: 100%"
          }
        },
        "87c045c64d954b729667c462627fda24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09e557922de2487697b92b8829343a72",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f6d85f5ab9fa46a39d46383325063e04",
            "value": 1
          }
        },
        "d97dd59afa184cfc88253ac09aa91d6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f59423cbf164f66b204ee49f1739040",
            "placeholder": "​",
            "style": "IPY_MODEL_b23856bfc734495b976eff1356432c6a",
            "value": " 55448/55448 [04:09&lt;00:00, 853.89 file/s]"
          }
        },
        "97815522a14f42a593c9c9e5cbc3f267": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3dce107f39db4529b141cde8f873858d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a6e44223043495599b3b66af106212c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "09e557922de2487697b92b8829343a72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "f6d85f5ab9fa46a39d46383325063e04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2f59423cbf164f66b204ee49f1739040": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b23856bfc734495b976eff1356432c6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}